
# Hypothesis Testing {#sec-hypothesis-testing}
  
In this chapter, we look at hypothesis testing \index{hypothesis testing} in R. We start with single sample distributions and tests, and then we look at hypothesis tests for comparing two samples. Examples include testing for positive correlations, performing two-sample paired t-tests, and testing for equal variance among groups. The data we use in this section comes from the Texas Health and Human Services Department and includes the reported number of induced terminations of pregnancy (ITOPs) from 2016 to 2021, stratified by both race and county [@itop]\index{Data sets!itop@\texttt{itop}}. The data also contains the rate of abortions per 1000 females aged 15-49. Read the data documentation to see the full variable descriptions.

We use the **tidyverse**\index{R packages!tidyverse}, **gt**\index{R packages!gt}, and **gtsummary**\index{R packages!gtsummary} packages to help manipulate and summarize the data. The **car** package\index{R packages!car} [@R-car] contains the function `leveneTest()` to implement a Levene's test for homogeneity of variance across groups, and all other hypothesis tests are available in base R.

```{r}
#| results: 'hide'
#| message: false
#| warning: false

library(tidyverse)
library(car)
library(HDSinRdata)
library(gt)
library(gtsummary)

data(tex_itop)
```

## Univariate Distributions and One-Sample Tests \index{hypothesis testing:one-sample tests}

Let's begin by looking at a single outcome of interest - the number of induced terminations of pregnancy (referred to as ITOPs or abortions below) in 2021 per 1000 females ages 15-49 in each county. We use the number of females ages 15-49 as a proxy to scale the number of abortions by the population size, though this is not truly reflective of the number of people who can give birth in each county.

```{r}
county_rates_2021 <- tex_itop$total_rate[tex_itop$year == 2021]
hist(county_rates_2021, breaks = 35)
```

We can see in the figure that this is a heavy-tailed distribution. In the following code, we find the 10 counties with the highest rates and see that there are some counties that very few total abortions but that have some of the highest abortion rates. This indicates a small population. On the other hand, we also observe Harris county, which contains the city of Houston and has both a high total abortion count and a high abortion rate.

```{r}
tex_itop %>% 
  filter(year == 2021) %>% 
  slice_max(n = 10, total_rate) %>%
  dplyr::select(c(county, total_itop, total_rate))
```

Some of the counties are so small that we may want to consider dropping them from our analysis. In particular, among these small counties the rates in Loving County and Terrel County are high enough that we might consider them to be outliers. For this one-sample analysis, however, we do not remove them. If we wanted to estimate the mean abortion rate among counties $\mu$ we can do so by simply using the `mean()` function. For reference, the Centers for Disease Control estimated the national abortion rate in 2020 to be 11.2 abortions per 1,000 women aged 15--44 years [@kortsmit2023abortion].

```{r}
mean(county_rates_2021, na.rm = TRUE)
```

Within R we can also calculate a confidence interval for this mean. Recall that a $(1-\alpha)$% confidence interval for the mean is given by the equation $\hat{\mu} \pm z_{1-\alpha/2} \cdot \frac{\hat{\sigma}}{\sqrt{n}}$, where $\hat{\mu}$ is our sample mean, $\hat{\sigma}^2$ is the sample variance, and $n$ is the number of observations.

In the subsequent code chunk, we use this formula to calculate a 95% confidence interval for the mean abortion rate among counties:

```{r}
est_mean <- mean(county_rates_2021, na.rm = TRUE)
est_sd <- sd(county_rates_2021)
z_alpha <- dnorm(1 - 0.05 / 2)
n <- length(county_rates_2021)
c(est_mean - z_alpha * est_sd / sqrt(n), 
  est_mean + z_alpha * est_sd / sqrt(n))
```

If we want to display this nicely, we can use the `round()` function, which allows us to specify a number of digits to be displayed, and the `paste()` function\index{R functions!paste()@\texttt{paste()}}, which creates a single character string from multiple inputs.

```{r}
lower <- round(est_mean - z_alpha*est_sd/sqrt(n), 3)
upper <- round(est_mean + z_alpha*est_sd/sqrt(n), 3)
paste("Confidence Interval: (", lower, ",", upper, ")")
```

Suppose that we wanted to run a hypothesis test to compare the mean to a pre-determined value. In particular, the Texas Heartbeat Act was introduced in 2021 and drastically reduced the number of eligible abortions. We could test whether there were significantly fewer abortions in 2021 compared to 2020 using a one-sided t-test. Our null hypothesis is that $\mu \geq 6.23$, the mean abortion rate in 2020. To run this hypothesis test, we use the `t.test()` \index{R functions!t.test()@\texttt{t.test()}} function. For a one-sample t-test, we need to specify our sample `x`, the alternative hypothesis `alternative` (default is a two-sided test), the true value of the mean `mu` (default 0), and a confidence level `conf.level` (default 0.95). In the following code, we run this t-test, and we can see from the result that we reject the null hypothesis at the 0.05 level and observe a statistically significant decline in the abortion rate in 2021.

```{r}
t.test(county_rates_2021, alternative = "less", mu = 6.23, 
       conf.level=0.95)
```

The output for this test is printed. If we want to reference these values, we need to save the result. The object `t_test_res` is a list that contains information about the statistic, p-value, confidence interval, etc. The list of outputs are similar to other test objects, so it is useful to look at what is contained in each by reading the test documentation (`?t.test`). We find the p-value from `t_test_res`.

```{r}
t_test_res <- t.test(county_rates_2021, alternative = "less", 
                     mu = 6.23, conf.level = 0.95)
names(t_test_res)
```

```{r}
t_test_res$p.value
```

### Practice Question

Test whether there were significantly more abortions in 2019 compared to 2020 using a one-sided t-test. Your test statistic should be -6.4736.

```{r}
# Insert your solution here:
```

One thing to consider is that the `t.test()` function assumes that the sample `x` comes from a normal distribution. The one-sample Wilcoxon signed rank test is a non-parametric alternative to the one-sample t-test that can be used to compare the median value of a sample to a theoretical value without assuming that the data are normally distributed. This test can be performed using the `wilcox.test()`\index{R functions!wilcox.test()@\texttt{wilcox.test()}} function and takes in the same arguments as the `t.test()` function. In the following output, we can see that we again reject the null hypothesis at the 0.05 level and conclude that the median abortion rate in 2021 was significantly lower than 5.14, which was the median rate in 2020.

```{r}
wilcox_res <- wilcox.test(county_rates_2021, alternative = "less", 
                          mu = 5.14, conf.level = 0.95)
wilcox_res
wilcox_res$p.value
```

## Correlation and Covariance \index{correlations} \index{covariance}

We now look at two-sample tests. To start, we look at the 2020 and 2021 rates by county. We pivot our data into a wider format in order to create 2020 and 2021 rate columns, and, this time, we filter out the Loving and Terrel counties to remove outliers. We then create a scatter plot of 2021 vs. 2020 rates and observe a linear correlation between the two.

```{r}
county_rates <- tex_itop %>%
  dplyr::select(c(county, total_rate, year)) %>%
  filter(!(county %in% c("Terrell", "Loving")), 
         year %in% c(2020, 2021)) %>%
  pivot_wider(names_from = year, values_from = total_rate) %>%
  na.omit() %>%
  rename("y2020" = "2020", "y2021" = "2021")
head(county_rates)
```

```{r}
ggplot(county_rates) + 
 geom_point(aes(x = y2020, y = y2021)) +
 labs(x = "2020 ITOP Rates", y ="2021 ITOP Rates")
```

We have seen before how to calculate the correlation between two columns using the `cor()`\index{R functions!cor()@\texttt{cor()}} function. We can also calculate the covariance using the `cov()`\index{R functions!cov()@\texttt{cov()}} function. As suspected, there is a positive correlation. The estimated covariance is around 5.2.

```{r}
cor(county_rates$y2020, county_rates$y2021)
cov(county_rates$y2020, county_rates$y2021)
```

Besides calculating the value of the correlation, we can also test whether this correlation is significantly different from zero. The function `cor.test()`\index{R functions!cor.test()@\texttt{cor.test()}} tests for association between paired samples, using either Pearson's product moment correlation coefficient, Kendall's $\tau$, or Spearman's $\rho.$ Similar to the `t.test()` and `wilcox.test()` functions, we can also specify the `alternative` and `conf.level` arguments. In the following code, we test whether there is a non-zero correlation between the 2020 and 2021 county rates using Pearson's product-moment correlation. We can see from the resulting p-value that we can reject the null hypothesis that the correlation is zero and conclude that it is instead significantly different than zero. This time we also print the computed confidence interval for our estimate.

```{r}
cor_test_res <- cor.test(county_rates$y2020, 
                         county_rates$y2021, 
                         method = "pearson")
cor_test_res
```

```{r}
cor_test_res$conf.int
```

## Two-Sample Tests for Continuous Variables \index{hypothesis testing:two-sample tests, continuous}

If we wanted to directly compare the difference between 2020 and 2021 rates, we could use a two-sample test. In this case, because our samples are paired by county, we can use a two-sample paired t-test. Specifically, we use a two-sided test to test the null hypothesis that the rates are equal by specifying two different vectors `x` and `y`. Note that we used the default values of `mu = 0` and `alternative = "two.sided"`. Additionally, we used the default value `var.equal = FALSE`, which implies that the samples may have different variances. From the results, we reject the null hypothesis that the two county rates are equal at the 0.05 level. We also print a 95% confidence interval of the difference in means.

```{r}
t_test_two_res <- t.test(x = county_rates$y2020, 
                         y = county_rates$y2021)
t_test_two_res
t_test_two_res$conf.int
```

In the `tex_itop` dataset, each county has also been categorized by whether it was urban or rural. Suppose we want to compare the change in abortion rates from 2020 to 2021 between rural and urban counties. First, we create a variable describing the rate change between these years using the following code. We choose to use the change in rate rather than percent change to avoid infinite or undefined values.

```{r}
county_rates_type <- tex_itop %>%
  dplyr::select(c(county, urban, county_type, total_rate, year)) %>%
  filter(total_rate < 15, year %in% c(2020, 2021)) %>%
  pivot_wider(names_from = year, values_from = total_rate) %>%
  na.omit() %>%
  rename("y2020" = "2020", "y2021" = "2021") %>%
  mutate(rate_change = (y2021 - y2020)) 
```

We again use a two-sample two-sided t-test, but this time the data are not paired. In the following code, we show an alternative way to specify a t-test test using a formula `lhs ~ rhs`, where `lhs` is a numeric column and `rhs` is a factor column with two levels. We must also specify the data in this case. From the R output in this case, we would fail to reject the null hypothesis at the 0.05 level and conclude that the rate changes for urban and rural counties are not significantly different. We also print the estimates used in the t-test using `estimate`, which shows the estimated mean in both groups.

```{r}
t_test_unpaired <- t.test(rate_change ~ urban, 
                          data = county_rates_type)
t_test_unpaired
t_test_unpaired$estimate
```

Note that this yields the same results as if we had specified the data using two vectors `x` and `y`.

```{r}
x <- county_rates_type$rate_change[county_rates_type$urban == 'Urban']
y <- county_rates_type$rate_change[county_rates_type$urban == 'Rural']
t.test(x = x, y = y, paired = FALSE) 
```

Besides a t-test, we can also use a two-sample Wilcoxon non-parametric test using the `wilcox.test()`\index{R functions!wilcox.test()@\texttt{wilcox.test()}} function, which has the same arguments as the function `t.test()`. Both the `t.test()` and `wilcox.test()` can only compare two groups. When we want to compare two or more independent samples, we can use a Kruskal-Wallis rank sum test using the `kruskal.test()`\index{R functions!kruskal.test()@\texttt{kruskal.test()}} function or a one-way analysis of variance (ANOVA) using the `aov()`\index{R functions!aov()@\texttt{aov()}} function.

This time we use the column `county_type`, which is an indicator for whether the county is urban, suburban, or rural according to the RUCC (rural-urban continuum codes) from the U.S. Department of Agriculture. For the `kruskal.test()` function, we can either specify the arguments `formula` (`rate_change ~ county_type`) and `data` (`county_rates_type`) or we can specify two vectors: `x`, a numeric vector, and `g`, a factor representing the group. For the `aov()` function, we specify the test using a formula and the data. To see the p-value, we have to use the `summary()`\index{R functions!summary()@\texttt{summary()}} function to print the result. Again, both tests suggest that we fail to reject the null hypothesis at the 0.05 level.

```{r}
kruskal.test(county_rates_type$rate_change, 
             county_rates_type$county_type)
```

```{r}
aov_res <- aov(rate_change ~ county_type, 
               data = county_rates_type)
summary(aov_res)
```

### Practice Question

Use an appropriate test to determine whether the ITOP rates in 2016 significantly differed by race. The test statistic should be 263.53 with associated p-value \< 2.2e-16.

```{r}
# Insert your solution here:
```

### Two-Sample Variance Tests

We could also test whether the variance of a continuous variable is equal between groups. To start, we compare the variance in abortion rates in 2021 between urban and rural counties using an F test. Our null hypothesis for this test is that the variance in both groups is equal. The function `var.test()`\index{R functions!var.test()@\texttt{var.test()}} implements an F test and has the same main arguments as the `t.test()` function: vectors `x` and `y` OR a `formula` and `data`, the alternative hypothesis `alternative`, and `conf.level`. Additionally, we can specify the hypothesized ratio of the variances through the argument `ratio` (default value 1). Note that this function assumes that the two samples come from normally distributed populations. We fail to reject the null hypothesis that the variance in rates are equal at the 0.05 level and print the estimate of the ratio of variances, which is around 1.11.

```{r}
f_test <- var.test(y2021 ~ urban, county_rates_type)
f_test
f_test$estimate
```

Lastly, we implement a Levene's test \index{R functions!leveneTest()@\texttt{leveneTest()}} to test whether group variances are equal when there are more than two groups. This test can be specified using a formula and data set, as demonstrated, or by providing two vectors `y`, a numeric vector, and `g`, a vector specifying the groups. This test is from the **car** package \index{R packages!car} and has slightly different output than other tests. In particular, to access the p-value, we need to access the value named `'Pr(>F)'`. In this case, we actually do reject the null hypothesis at the 0.05 level.

```{r}
levene_test <- leveneTest(y2021 ~ as.factor(county_type), 
                              county_rates_type)
print(levene_test)
levene_test[['Pr(>F)']]
```

## Two-Sample Tests for Categorical Variables \index{hypothesis testing:two-sample tests, categorical}

In the previous two-sample tests, we were comparing the distributions of continuous variables. We now look at comparing distributions of categorical variables. We first categorize counties by their abortion rate in 2020 being above or below 11.2, which was the national average rate that year. We display the distribution of this variable by the urban/rural grouping using a contingency table below.

```{r}
county_rates_type$below_nat_avg <- 
  ifelse(county_rates_type$y2020 > 11.2, "Above Nat Avg", 
         "Below Nat Avg")
table(county_rates_type$below_nat_avg, county_rates_type$urban)
```

We can use a Fisher's exact test to test whether the classifications of being above and below the national average and being rural and urban are associated with each other. In this case, the null hypothesis is that the odds or being below the national average is equal between rural and urban counties. The `fisher.test()`\index{R functions!fisher.test()@\texttt{fisher.test()}} function can either take in a contingency table as a matrix or can be specified by two factor vectors `x` and `y`, which is how we implement it in the following code. Additionally, there is the option to specify the `alternative` and `conf.level` arguments. We do not see a statistically significant difference between urban and rural counties at the 0.05 level with the estimated odds ratio is around 0.23.

```{r}
fisher_test <- fisher.test(county_rates_type$urban, 
                           county_rates_type$below_nat_avg)
fisher_test
fisher_test$estimate
```

An alternative test is a Pearson's Chi-Squared test, which can be used for large sample sizes. The counts of rural and urban counties in the 'Above Nat Avg' category are very small, so we recategorize our outcome to be at or above Texas's average to avoid this complication. The `chisq.test()`\index{R functions!chisq.test()@\texttt{chisq.test()}} function also takes in a contingency table as a matrix or can be specified by two factor vectors `x` and `y`. Another useful argument is `correct` (default is TRUE) which indicates whether to apply a continuity correction. For this test, we observe a statistically significant difference in the proportion of counties above the national average between rural and urban counties and reject the null hypothesis at the 0.05 level.

```{r}
tex_mean <- mean(county_rates_type$y2020)
county_rates_type$below_tex_avg <- 
  ifelse(county_rates_type$y2020 > tex_mean, "Above Texas Ave", 
         "Below Texas Ave")
table(county_rates_type$below_tex_avg, county_rates_type$urban)
```

```{r}
chi_sq <- chisq.test(county_rates_type$below_tex_avg, 
           county_rates_type$urban)
chi_sq
chi_sq$p.value
```

### Practice Question

Repeat the Chi-Squared test, but this time use the RUCC codes instead of the `urban` column. You should get a p-value of 0.2799. Think about what could explain the difference between these results.

```{r}
# Insert your solution here:
```

## Adding Hypothesis Tests to Summary Tables \index{summary tables}

In [Chapter -@sec-exploratory], we used the **gt** \index{R packages!gt} and **gtsummary** packages \index{R packages!gtsummary} to create summary tables of variables. When creating a stratified table (done by adding the `by` argument), we can automatically add p-values for hypothesis tests comparing across populations using the `add_p()`\index{R functions!add\textunderscore p()@\texttt{add\textunderscore p()}} function. By default, the `add_p()` function uses a Kruskal-Wallis rank sum test for continuous variables (or a Wilcoxon rank sum test when the `by` variable has two levels) and uses a Chi-Squared Contingency Table Test for categorical variables (or a Fisher's Exact Test for categorical variables with any expected cell count less than five). The chosen test(s) are displayed as footnotes.

```{r}
#| eval: false

tbl_summary(tex_itop, include = c(total_rate, white_rate, asian_rate, 
                                  hispanic_rate, black_rate, 
                                  native_american_rate),
           by = "year", 
           statistic = list(all_continuous() ~ "{mean} ({sd})")) %>% 
  add_p() %>%
  as_gt() 
```

![Summary Table Stratified by Year.](images/hypothesis_tests/gt-summary-table.png){#fig-gt-summary-table fig-align="center" width="100%"}

We observe that a Kruskal-Wallis rank sum test was used to compare abortion rates across year for each racial group. All of the reported p-values are above 0.05 so overall it indicates that there were not statistically significant changes across years in the abortion rate.

::: {.content-visible when-format="html"}
## Recap Video

{{< video https://www.youtube.com/embed/3vyCeUdSS6U width="700" height="500" >}}
:::


## Exercises

For the following exercises, we use the `pain` data\index{Data sets!pain@\texttt{pain}} from the **HDSinRdata** package\index{R packages!HDSinRdata}.

```{r}
data(pain)
```

1.  Determine whether the presence or absence of follow-up information is significantly associated with the initial average pain intensity. What do the results suggest?

2.  First, plot `PROMIS_PAIN_BEHAVIOR` grouped by race (you can use the `PAT_RACE_CAT` variable that we defined in [Chapter -@sec-ggplot2]. What do you observe? Next, choose an appropriate test to determine whether this variable differs significantly by race.

3.  Examine the association between `CCI_BIN` and `MEDICAID_BIN`. Are these variables significantly related to each other? How would you describe their relationship?

4.  Recreate the summary table in @fig-pain-stratified-summary. Then, recreate the p-values for `PROMIS_DEPRESSION`, `PROMIS_ANXIETY`, and `MEDICAID_BIN` using the appropriate tests.

  ![Stratified Summary Table.](images/hypothesis_tests/pain-stratified-summary.png){#fig-pain-stratified-summary fig-align="center" width="100%"}


